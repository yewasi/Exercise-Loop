{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtVtTogAq9KYxM5ngfucCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yewasi/Exercise-Loop/blob/master/Text_Analysis_Using_NLP_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fShfbQ3MQ2n",
        "outputId": "941960a6-2356-4b15-cb47-389e32b86964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Downloading NLTK data for NER\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Downloading NLTK data for NER\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Sample business document\n",
        "business_document = \"\"\"\n",
        "The recent feedback from Acme Corp highlighted issues with the new model of the Omega widget.\n",
        "Customers from New York and San Francisco have reported delays in shipping.\n",
        "The CEO of Acme Corp, Jane Doe, mentioned plans to address these concerns by Q3.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenizing the document\n",
        "tokens = nltk.word_tokenize(business_document)\n",
        "\n",
        "# Applying NER\n",
        "ner_result = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
        "\n",
        "# Printing named entities\n",
        "print(\"Named Entities:\")\n",
        "for entity in ner_result:\n",
        "    if isinstance(entity, nltk.Tree):\n",
        "        print(\" \".join([word for word, tag in entity.leaves()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_TTrz1VNimk",
        "outputId": "eb0157bf-4c48-4356-8bcc-502649d8d4e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Acme Corp\n",
            "Omega\n",
            "New York\n",
            "San Francisco\n",
            "CEO of Acme Corp\n",
            "Jane Doe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Downloading NLTK data for NER\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Sample business document\n",
        "business_document = \"\"\"\n",
        "I think you did a great job when you ran the all-hands meeting. It showed that you are capable of getting people to work together and communicate effectively. I admire your communication skills.\n",
        "Clients from Africa and Asia gave this during the annual meeting. This is the feedback received from the COO of Dovina Technologies, Sam Anfi, mentioned plans to address these concerns by Q3.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenizing the document\n",
        "tokens = nltk.word_tokenize(business_document)\n",
        "\n",
        "# Applying NER\n",
        "ner_result = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
        "\n",
        "# Printing named entities\n",
        "print(\"Named Entities:\")\n",
        "for entity in ner_result:\n",
        "    if isinstance(entity, nltk.Tree):\n",
        "        print(\" \".join([word for word, tag in entity.leaves()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPEgxzccNrp-",
        "outputId": "e5e90801-b6cb-441f-d348-35e92d5dc196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Clients\n",
            "Africa\n",
            "Asia\n",
            "COO\n",
            "Dovina Technologies\n",
            "Sam Anfi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing named entities along with their categories\n",
        "print(\"\\nNamed Entities with Categories:\")\n",
        "for entity in ner_result:\n",
        "    if isinstance(entity, nltk.Tree):\n",
        "        entity_name = \" \".join([word for word, tag in entity.leaves()])\n",
        "        entity_category = entity.label()\n",
        "        print(f\"{entity_name}: {entity_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvEegIJCO7i-",
        "outputId": "1540a82c-2c70-4b37-a2b1-99d098a277a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Named Entities with Categories:\n",
            "Clients: PERSON\n",
            "Africa: GPE\n",
            "Asia: GPE\n",
            "COO: ORGANIZATION\n",
            "Dovina Technologies: GPE\n",
            "Sam Anfi: PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Sample business document\n",
        "business_document = \"\"\"\n",
        "The recent feedback from Acme Corp highlighted issues with the new model of the Omega widget.\n",
        "Customers from New York and San Francisco have reported delays in shipping.\n",
        "The CEO of Acme Corp, Jane Doe, mentioned plans to address these concerns by Q3.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenizing the document\n",
        "tokens = nltk.word_tokenize(business_document)\n",
        "\n",
        "# Applying POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Printing words and their POS tags\n",
        "print(\"Words and POS Tags:\")\n",
        "for word, tag in pos_tags:\n",
        "    print(f\"{word}: {tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKJvu-H5P2J7",
        "outputId": "53d3c5c7-b42a-4e6f-a528-93ffa4daf7eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words and POS Tags:\n",
            "The: DT\n",
            "recent: JJ\n",
            "feedback: NN\n",
            "from: IN\n",
            "Acme: NNP\n",
            "Corp: NNP\n",
            "highlighted: VBD\n",
            "issues: NNS\n",
            "with: IN\n",
            "the: DT\n",
            "new: JJ\n",
            "model: NN\n",
            "of: IN\n",
            "the: DT\n",
            "Omega: NNP\n",
            "widget: NN\n",
            ".: .\n",
            "Customers: NNS\n",
            "from: IN\n",
            "New: NNP\n",
            "York: NNP\n",
            "and: CC\n",
            "San: NNP\n",
            "Francisco: NNP\n",
            "have: VBP\n",
            "reported: VBN\n",
            "delays: NNS\n",
            "in: IN\n",
            "shipping: NN\n",
            ".: .\n",
            "The: DT\n",
            "CEO: NN\n",
            "of: IN\n",
            "Acme: NNP\n",
            "Corp: NNP\n",
            ",: ,\n",
            "Jane: NNP\n",
            "Doe: NNP\n",
            ",: ,\n",
            "mentioned: VBD\n",
            "plans: NNS\n",
            "to: TO\n",
            "address: VB\n",
            "these: DT\n",
            "concerns: NNS\n",
            "by: IN\n",
            "Q3: NNP\n",
            ".: .\n"
          ]
        }
      ]
    }
  ]
}